\chapter{Estudo de Caso}
\label{cap-case-study}

%

Neste capítulo será apresentada a utilização dos Cenários de Decisões em projetos reais, com o principal objetivo de demonstrar a reprodução de cenários em ambientes de tomada de decisão. Assim, este Capítulo é destinado ao Estudo de Caso de utilização das ferramentas Mezuro e DWing para observação de Cenários de Decisões em projetos de software.

Para tanto, será apresentada a avaliação de três projetos de softwares livres em C++. Além disso, iremos explicar os passos necessários para reproduzir a estrutura de cenários nos dois ambientes de tomadas de decisões abordados nesta monografia. Assim, será apresentado as principais evoluções e adaptação de cada ferramenta e os detalhes específicos da observação de cada cenário.

O método de execução desses estudos de casos é apresentado na Figura~\ref{method}. Nesta figura são descritos os passos necessários para reproduzir cenários em ferramentas que apoiam a tomada de decisões baseados em métricas de software que, no contexto desta monografia, consiste no Mezuro e DWing.

\graphicspath{{figuras/}}
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{fluxograma}
\caption{Método para execução dos estudos de casos.}
\label{method}
\end{figure}

Os passos da Figura~\ref{method} são melhor descritos a seguir:

\begin{enumerate}
\item \textbf{Adaptar e Evoluir Ferramentas} - Este passo consiste em evoluir as estruturas, modelos, componentes e camada de apresentação das ferramentas que serão utilizadas com o objetivo de melhor suportar a utilização de Cenários de Decisão.
\item \textbf{Reproduzir Cenários} - Uma vez que as ferramentas utilizadas já suportam a reprodução de Cenários, deve-se utilizar dessa estrutura para definir cenários reais para avaliação de projetos de software. No contexto dessa monografia, esse passo consiste em reproduzir os Cenários de Segurança criados no Mezuro e no DWing.
\item \textbf{Selecionar Projetos} - Esta etapa consiste em definir quais projetos serão avaliados a partir dos cenários definidos e pode ser executada independente das ferramentas de tomada de decisão, variando de acordo com os objetivos de utilização dos Cenários.
\item \textbf{Obter Código-Fonte} - Uma vez selecionados os projetos, o próximo passo é obter o código-fonte referente aos projetos escolhidos. Algumas ferramentas. como o Mezuro, já possuem bom suporte para automatizar esse passo.
\item \textbf{Executar Coleta} - Esta etapa consiste na obtenção dos valores de métricas dos códigos-fontes dos projetos selecionados que deve ser automatizado. A saída desta etapa deverá ser processada pelas ferramentas trabalhadas para proporcionar a análise dos projetos. O esforço nessa etapa deve-se reduzir a coletar somente as métricas necessárias para composição dos Cenários de Decisão utilizados.
\item \textbf{Analisar Cenários} - A partir dos resultados obtidos, deve-se utilizar os Cenários de Decisão para observar as características do estado atual do projeto analisado. No contexto desse trabalho, esta etapa consiste em analisar quais os principais módulos oferecem riscos de segurança ao software.
\item \textbf{Realizar Conclusões} - Esta etapa final consiste em realizar ações a partir da compreensão dos Cenários observados, seja para fins de estudos ou para fins de desenvolvimento do software. 
\end{enumerate}


Estes passos metodológicos devem ser reproduzidos para cada ferramenta utilizada, sendo que uma vez que uma ferramenta já suporta adequadamente a observação de Cenários de Decisão, os passos 1 e 2 não precisam ser repetidos para análise de novos projetos.


\section{Criação dos Cenários do Mezuro}
\label{mezuro-cenarios}

O Mezuro é uma plataforma livre para monitoramento de código-fonte que busca auxiliar em vários problemas relacionados à utilização de métrica, visando ser uma interface que permita, de forma flexível, a extração e análise de métricas estáticas de código-fonte, licensiado como AGPLv3\footnote{\url{http://www.gnu.org/licenses/agpl-3.0.html}} \cite{manzo2014}. O Mezuro é uma plataforma concebida através do amadurecimento de diversas ferramentas, inicializada através do projeto Qualipso\footnote{Quality Platform for Open Source: \url{http://qualipso.icmc.usp.br/}}. Dentre estas ferramentas, destaca-se o Analizo\footnote{\url{http://analizo.org/}}, uma das ferramentas utilizadas pelo Mezuro para extração de métricas de código-fonte em C/C++ e Java.

A arquitetura do Mezuro atual é composta por vários serviços. Essa arquitetura está evoluindo para uma arquitetura de composição de três serviços principais que se resumem em:

\begin{itemize}
\item \textbf{Prezento}: Camada de apresentação da plataforma, desenvolvida em Ruby on Rails.

\item \textbf{Kalibro Gatekeeper}: Serviço que faz a intermediação e orquestração das outras camadas com o Prezento.

\item \textbf{Kalibro Processor}: Serviço que centraliza o processamento de métricas de projetos.

\item \textbf{Kalibro Configuration}: Serviço responsável pelo processamento de configurações.
\end{itemize}

Uma explicação mais detalhada desta arquitetura e de cada serviço pode ser obtida no Apêndice \ref{Att:mezuro}.

Dois destes serviços agregam conceitos fundamentais dentro da plataforma, que também serão muito importantes para a representação de cenários dentro da plataforma. 

O Kalibro Configuration contempla o conceito de configuração que é um conjunto de métricas e parâmetros que podem ser utilizadas para a avaliação de um projeto. Uma configuração consiste, portanto, na composição de métricas cujos valores de referência são flexíveis e podem ser determinados separadamente para cada configuração criada. Associado ao conceito de configuração, está a criação de intervalos qualitativos associado a valores de métricas. Este módulo ainda é complementado por \emph{Reading Gropus} que são grupos de leituras definidos por usuários que associam nomes qualitativos à cores que podem ser utilizados em configurações a partir na definição de intervalos de valores. Esta característica é muito importante para a utilização das métricas, uma vez que abstraem a interpretação direta dos valores obtidos para definições mais simples como bom, regular e ruim. Assim, tem-se a flexibilidade de ter parâmetros que variam de acordo com a linguagem, natureza do software, dentre outras coisas, apenas pela criação de diferentes configurações. 

O Kalibro Processor contempla o módulo de extração e processamento de métricas de código-fonte. Para que esse processamento seja realizado, o Kalibro Processor realiza o download de projetos que estão em repositórios GIT ou SVN e utiliza uma ou mais ferramentas de extração de métricas, como mencionado anteriormente. Assim, obtem-se a partir da análise estática do código-fonte um conjunto de métricas nativas que podem ser compostas para formular métricas mais complexas e de maior valor interpretativo. Dentro do Mezuro, esta abordagem é realizada através da criação de métricas compostas as quais serão muito importantes para a definição de Cenários de Decisões. 

Atualmente, o Mezuro pode monitorar projetos em C, C++ e Java uma vez que utiliza o Analizo como seu principal extrator de métricas. Entretanto, com a evolução da plataforma, pretende-se acoplar novos extratores na ferramenta para outras linguagens de programação.

Descrevemos a seguir os passos necessários para a utilização de Cenários de Decisões no Mezuro referente a realização da etapa Reproduzir Cenários do estudo de caso. Todas as etapas exigem que haja um usuário autenticado no sistema.

\begin{description}
	\item[Criação do \emph{Reading Group} para os Cenários]
\end{description}

A criação de um \emph{Reading Group} para abstrair a interpretação do cenário é o primeiro passo para adaptação de cenários na ferramenta. Portanto, foi criado um grupo\footnote{\url{http://mezuro.org/reading_groups}} que define duas opções para a leitura de resultados binários, a fim de mostrar se existe ou não um cenário, usando a cor verde para a resposta falsa e vermelho para a resposta verdadeira. Este grupo é criado independente de configurações ou projetos dentro do Mezuro, de tal forma que pode ser utilizado por qualquer configuração que venha a reproduzir cenários. O grupo criado por de ser visto na Figura \ref{reading_group}.

\graphicspath{{figuras/}}
\begin{figure}[h]
\centering
\includegraphics[width=1.0\textwidth]{reading_group}
\caption{Reading Group criado para Cenários. Disponível no Mezuro.org \url{http://mezuro.org/reading_groups/7}}
\label{reading_group}
\end{figure}

\begin{description}
	\item[Criação de uma Configuração para uma categoria de Cenários]
\end{description}

Nesta etapa deve-se criar uma configuração onde serão definidos todos os cenários que queremos avaliar em conjunto. Como exemplo, teríamos a opção de criar um único cenário que contemple todos os Cenários de Segurança que usam métricas de \emph{design} (\ref{cenarios-design}) e os Cenários de Segurança que usam métricas de vulnerabilidade (\ref{cenarios-vulnerabilidades}), da mesma forma que poderíamos criar uma configuração separada para cada tipo de cenário. O que mudaria é que, no primeiro o projeto seria monitorado uma única vez, enquanto no segundo o projeto deveria ser monitorado duas vezes, uma para cada configuração. 

Sugere-se que a segunda abordagem seja utilizada, pois flexibiliza mais o monitoramento a partir de cenários, uma vez que existem diversos projetos com diversos interesses diferentes. Além disso, vale ressaltar que uma configuração deve contemplar apenas uma linguagem de programação e domínio, uma vez que os parâmetros de avaliação dos Cenários irão variar de acordo com o contexto.

A criação de uma configuração é bem simples, pois deve-se informar apenas o nome e a descrição da configuração\footnote{\url{http://mezuro.org/mezuro_configurations}}. Assim, criou-se a configuração entitulada "Cenários de Decisões - Design Seguro para C++" para a categoria de cenários descrita em (\ref{cenarios-design}).





explicar primeiro como o Mezuro foi utilizado para suportar os Cenários, o que foi adaptado e melhorado para melhor suportar cenários, etc.

Depois deve-se mostrar a estrutura de cada cenário dentro da ferramenta (scripts e configuração)

\section{Criação dos Cenários do DWing}
\label{dw-cenarios}

Como o nome sugere, \emph{Data Warehouse} (DW), em português, significa armazém de dados. Segundo Inmon (\citeyear{inmon2002}) um \emph{Data Warehouse} é uma coleção de dados de uma coorporação que tem como objetivo dar suporte a tomada de decisão. 
%
O DW possibilita a análise de grandes volumes de dados, fazendo com que ele seja o núcleo de muitas soluções de \emph{Business intelligence} (BI)
%
\footnote{\emph{Business intelligence} é o processo de coleta, organização, análise, compartilhamento e monitoramento de informações, oferencendo suporte a gestão de negócios}. 
%

Neste trabalho procuramos desenvolver mecanismos que nos permitam monitorar e analisar o código fonte através de métricas de forma automatizada e que nos auxilie na tomada de decisão de refatorar ou não refatorar determinadas partes do código. 
%
Nesse sentido, foram encontrados alguns trabalhos na literatura que utilizaram o DW para monitorar métricas de processos e produtos de software \cite{Folleco2007} \cite{Silveira2010}\cite{mazuco2011}. Dentre estes, o que se destaca é o trabalho de  \cite{Silveira2010} que propõe um processo automatizado de extração e carga em um repositório central de métricas de qualidade de software. O autor também oferece suporte a monitoração dos projetos utilizando a técnica EVA e a análise da qualidade interna do software para o auxilio a tomada de decisões sobre os projetos analisados. 

Outro trabalho que tem destaque e que serviu como ponto de partida para a criação do modelo dimensional do ambiente de DWing desta monografia foi o trabalho de \cite{rego2014}. Este propõe um ambiente de DWing que além de monitorar métricas de um projeto,  identifica e monitora cenários compostos por métricas relacionados a qualidade de software.

% 
O fato de o DW oferecer um alto poder de análise e poder tratar uma grande quantidade de dados nos faz ter uma espectativa de que esse ambiente pode ser uma solução mais completa em termos de monitoramento e auxílio na tomada de decisão. Entretanto, temos a hipótese de que o DW seja uma solução mais adequada para o uso por gerentes ou líderes de projeto, diferente do Mezuro que poderia ser melhor utilizado no uso cotidiano dos desenvolvedores. Mas essas são apenas hipóteses que serão validadas com a real comparação entre os dois ambientes implementados.

O conjunto de ferramentas de manipulação de dados, desde sua extração até a visualização para o apoio a consultas e tomada de decisição é denominado de \emph{Data Warehousing} (DWing). Portanto,  \emph{DWing} não são as tecnologias em si envolvidas e sim uma arquitetura que requer o suporte de diferentes tipos de tecnologias \cite{inmon2002}.  As principais tecnologias envolvidas em um ambiente de \emph{DWing} são:


\begin{itemize}
\item SGBDS – Gerenciadores de bases de dados
\item Sistemas de conversão e transformação de dados (ferramentas de ETL)
\item Tecnologias cliente e servidor para dar acesso aos dados a múltiplos clientes
\item Ferramentas de análise e geração de relatórios.
\end{itemize}


Kimball (\citeyear{kimball2002}) define os componentes básicos de um ambiente de \emph{DWing} conforme a Figura \ref{componentesdw}.

 \begin{figure}[!htb]
 	\centering
 		\includegraphics[scale=0.5]{figuras/componentesDW}
 		\caption{Componentes de um \emph{DWing}. Adaptação de \cite{kimball2002}}.
 		\label{componentesdw}
 \end{figure}


%TODO: ver se concorda com o fato de não termos subseções aqui
% a figura acima estava sem explicação/interpretação "explicita"
 A extração dos dados que irão compor o DW é feita de fonte de dados de sistemas, podendo ser de um ou vários sistemas relacionados. Esses dados são tratados na DSA, onde podem ser combinados, limpados ou transformados, tornado-os mais consistentes para que possam então ser amazenados na DPA, que seriam o DW ou \emph{Data Mart's}
 %
 \footnote{\emph{Data Mart} é um subconjunto de dados de um DW. Foca em uma ou mais áreas específicas \cite{kimball2002}}. 
 %
 As ferramentas de acesso são as responsáveis pela análise dos dados, podendo realizar consultas, gerar relatórios entre outros mecanismos de visualização.

Dado cada componente que compõe um ambiente de DWing, a seguir iremos detalhar algumas características de cada um deles já aplicando a criação do ambiente de DWing construido neste trabalho.

\subsection{Sistemas de fonte de Dados}

Os Sistemas de Fonte de Dados são os sistemas que irão fornecer os dados para o ambiente de DWing. No contexto dessa monografia, queremos colher métricas de software para fazer a análise e identificar a existência dos cenários definidos. Dessa forma, o Analizo é considerado um sistema de fonte de dados, pois fornece um relatório CSV com os valores das métricas de um projeto. O Analizo fornece tanto as métricas de qualidade quanto as métricas de vulnerabilidades utilizadas nos cenários propostos. 

Porém, foi identificado um problema com o Analizo de forma com que, para projetos maiores, ele não consegue gerar as métricas de vulnerabilidade. Esse problema será explicado mais adiante na seção (\ref{data-colect}). Mas uma característica de um ambiente de DWing é ser integrado. Isso quer dizer que um DWing é capaz de integrar dados de diversas fontes. Dessa forma, foi utilizado o clang-static-analyzer para coleta das métricas de vulnerabilidades usadas nos cenários propostos.


\subsection{Area de Apresentação - DPA}

Antes de falar do DSA, vamos falar do DPA que é a camada que é definida pelo \emph{Data Warehouse} em si. É preciso ter uma base de dados onde irá ser armazenado todos os dados que é de interesse do negócio que se quer monitorar. Isso revela uma outra característica importante de um ambiente de DWing, que é ser orientado a assuntos, ou seja, fornecer apenas os dados que são interessantes para o negócio.

A base de dados de um DW difere de uma base de dados que é utilizada normalmente em aplicações, que são derivadas muitas vezes de uma modelagem relacional. Essas bases são modeladas e construídas de maneira normalizada, buscando relacionar os dados de maneira que não haja redundância de informação e que facilite operações OLTP (operações transacionais) como inserção de dados, alteração e exclusão. Porém, um DW é construído baseado em outro tipo de modelagem, que é conhecida como Modelagem Dimensioal.

Segundo Kimball \citeyear{kimball2002} a modelagem dimensional é a única técnica viável para banco de dados  que devem responder a consultas em um DW.

A modelagem dimensional é mais simples, mais expressiva e mais fácil de compreender do que a modelagem relacional \cite{ballard1998}. A modelagem dimensional busca obter um modelo que representa um conjunto de medidas que são descritas por aspectos comuns de negócio.
%
Os conceitos básicos da modelagem dimensional são "fatos", "dimensões" e "medidas". Resumidamente, "fatos" são os dados que contém as medidas do contexto, ou seja são instâncias da realidades que podem ser mensuradas de maneira quantitativa \cite{kimball2002}. No contexto dessa monografia, estamos querendo identificar os cenários de decisões encontrados em um projeto, sendo assim, o "fato" que queremos é a quantidade cenários encontradas em um projeto, em uma determinada release, coletado em uma data específica, etc. Outro "fato" interessante é saber a qual o valor de algumas métricas que compõe os cenários daquele projeto em determinado período. 

O conceito de "Dimensões" está relacionado aos dados que determinam alguns detalhes a respeito do fato colhido. Nesse sentido, o nome do projeto, a data em que foi coletado a quantidade de cenários, a release em que foi feito a análise, qual foi o cenário em si que foi contado, efim, todas essas informações caracterizam o "fato" de quantidade de cenários obtida em uma classe, por exemplo.  


O conceito de "medidas" fica explícito no "fato", sendo o atributo numérico do fato, que no caso é a quantidade de cenários de decisões e o valor das métricas em cada classe. 


A modelagem dimensional utiliza esses conceitos de "fatos" e "dimensões", de forma que existe uma tabela central do esquema que serve para armazenar os fatos e esta se relaciona com as demais tabelas dimensões, que fornecem as características dos fatos. Dessa forma, a tabela fato é composta apenas pela medida coletada e as chaves para as demais dimensões que possuem dados que caracterizam essa medida. Esse tipo de esquema gerado pela modelagem dimensional é chamado de esquema estrela (star-scheme). Mais detalhes sobre características de fatos e dimensões podem ser encontradas no apendice.



As vantagens desse tipo de modelagem é que os dados não são normalizados, e isso traz performance para consultas OLAP, que são consultas de caráter analítico. As dimensões são desnormalizadas, gerando redundancia de dados. Por exemplo, o nome de um cenário é uma caracterísca do fato de quantidade de cenários encontrados. Como definido nessa monografia, temos cenários de dois tipos: que identificam características de qualidade e que identificam vulnerabilidades específicas. Logo, podemos perceber que a dimensão "Cenário" terá atributos como o nome do cenário e tipo do cenário. O atributo "tipo do cenário" ficará repedindo em diferentes tuplas da tabela dimensão, porém isso irá evitar a realização de joins que seriam feitos para combinar esses dados. Joins são operações muito custosas, e se tratando de consultas de caráter analítico, que processam uma grande quantidade de dados, essa característica não se torna interessante para um ambiente de DWing.


Para partirmos para modelagem de nosso DW,  precisamos então ter definido as necessidades do negócio. No caso dessa monografia, queremos conseguir monitorar e visualizar quais os cenários estão ocorrendo no projeto e também monitorar o valor de suas métricas que estão envolvidas nos cenários, de modo que, ao identificar que um determinado cenário está acontecendo, eu possa também identificar as métricas que estão relacionadas com a ocorrência do cenário, ajudando assim a identificar quais ações devemos tomar para solucionar essa ocorrência. Dessa forma, temos dois fatos claros: (1) um fato para registrar a quantidade de cenários e (2) outro para registrar o valor das métricas.

No trabalho de Rego \citeyear{rego2014} podemos ver que a modelagem proposta atende muitos aspectos da modelagem que se pretendia chegar nesta monografia. Baseado nisso, chegamos a essa modelagem mostrada na figura TAL para o DW deste trabalho.

=================COLOCAR FIGURA dos esquemas ====================


Alguns aspectos da modelagem do trabalho de Rego (\citeyear{rego2014}) foram modificados para atender melhor a definição dos cenários de decisões proposta nessa monografia. A tabela fato de cenários foi modelada de maneira muito semelhante a do trabalho de Rego. Porém, foram adicionadas a dimensão tempo e de sprints. Uma das principais características de um ambiente de DWing é permitir a análise temporal dos dados, logo viu-se a necessidade da inclusão da dimensão tempo. Dessa forma, será permitido analisar os cenários ao longo do tempo. 

Outra modificação importante foi feita na dimensão cenários. Para representar os cenários de decisões achamos importante colocar os atributos que definem a estrutura de um cenário proposta nesse trabalho. Dessa forma, incluimos os atributos tipo do cenário, métricas envolvidas, formula e uma descrição. Uma limitação do trabalho de Rego foi que os cenários só podiam ser compostos por no máximo duas métricas. Isso se dá ao fato de que Rego utilizou os metadados para definir quais métricas estavam envolvidas a cada cenário. No nosso caso, levando em conta que  metadados não são disponibilizados para o usuário, preferimos criar o atributo "metricas\_envolvidas" na dimensao d\_scenario, permitindo assim acesso ao usuário em saber quais métricas estão relacionadas à aquele cenário, permitindo que ele possa verificar os valores dessas métricas nos outros fatos de métrica, e também que um cenário possa ser definido independente do número de métricas envolvidas. O atributo formula por sua vez, indica a relação entre as métricas envolvidas para a caracterização do cenário.


Rego também criou outro fato para armazenar os valores percentis das métricas do projeto. Para este trabalho, achamos que seria melhor o fato de métricas ser no nível de módulo. Dessa forma, permite ao usuário que possa identificar a causa de um cenário. Por exemplo, suponhamos que o usuário tenha identificado a ocorrencia do cenário "Ponto crítico de falha" em um determinado módulo. Posteriormente, o usuário pode verificar qual foi o valor das métricas ACC e NOC nesse módulo e tomar uma decisão de refatoração baseado nos valores dessas métricas. No trabalho de Rego, como os valores das métricas estariam disponíveis ao nível de projeto apenas, esse tipo de análise não poderia ser feito.

Em nossa modelagem, preferimos semparar em dois fatos as métricas de qualidade e as métricas de segurança. A motivação foi que esses dois tipos de métricas possuem natureza diferente. Métricas de vulnerabilidade contam o número de ocorrência de uma determinada vulnerabilidade no código. Logo, podemos realizar agregações e descobrir a quantidade de vulnerabilidade por arquivo, por projeto, etc. Já com métricas de qualidade, não podemos fazer agregações. Não faz sentido, por exemplo, somar o valor de complexidade ciclomatica de todas os módulos para obter o valor do projeto. A média seria a único tipo de agregação que poderia ser feita, porém o uso da média é confrontado pela tese de Meireles, fazendo que nem esse tipo de agregação possa ser feito em cima das métricas de qualidade. E como discutido no capítulo de CENÀRIOS, nao temos um índice de qualidade para métricas de vulnerabilidade, fazendo que essa dimensão não seja utilizada na fato f\_security\_metrics. Por outro lado, é possível chegar ao nível de linha para caracterizar uma vulnerabilidade, incluindo então a dimensão d\_line\_number a esse fato.

Dado o modelo, decidimos por usar o banco de dados MariaDB para a implementação deste.



\subsection{Área de Armazenamento - DSA}

A área de armazenamento é responsável pela extração, transformação e carga dos dados provenientes das fontes de dados para o DW em si. Esse processo é comummente conhecido como ETL. Uma série de transformações podem ser feitas buscando a limpeza de dados (resolução de conflitos, tratamento de informações não existente, conversão de dados para um formato padronizado), combinação de dados de diversas fontes, remoção de dados duplicados e atribuições de chaves que serão utilizadas no DW \cite{kimball2002}.

%
No nosso ambiente de DWing, os dados são disponibilizados na forma de arquivos CSV. O relatória de métricas do clang é disponibilizado em formato html, porém, a fim de facilitar a extração desses dados, foi criado um parser para transformar esse relatório em um arquivo CSV.


Para o processo de ETL foi utilizado uma ferramenta da suíte de ferramentas Pentaho, chamada de \emph{Pentaho Data Integration} (PDI). O PDI aceita diversos formatos de entrada de Dados, além de fazer integração com diversos banco de dados, incluindo o MariaDB, que foi utilizado para a implementação do DW.


O PDI possui dois tipos de componentes, que são Job e Transformation. Os Jobs permitem executar tarefas como estabelecer um fluxo de controle, executar Transformations, mandar um email em caso de falha, entre outros. As Transformations são responsáveis por implementar os mecanismos de ETL, possibilitando a extração de arquivos de diversos formatos, manipulação dos dados de diversas formas e carga em bases de dados que compõe o DW.


Neste trabalho não conseguimos criar Jobs para fornecer as facilidades e vantagens que ele oferece. Criamos apenas Transformations que são responsáveis pela extração e carga dos dados das dimensões do modelo e dos fatos. Dessa forma, as Transformations que tem a responsabilidade de identificar os cenários de decisões e carrega-los na tabela de fatos. A figura TAL mostra um trecho da Tranformation criada para identificação de cenários de decisões.


COLCAR FIGURA DA TRANSFORMACAO DE CENARIOS


Cada componente de uma transformation é denominado um step. De maneira resumida, os dados são extraidos de arquivos CSV. Esses dados contém as classes ( modulos) e o valor das métricas para cada classe. Para cada cenário, são selecionadas apenas as métricas de interesse para verificar se o cenário existe o não. Então, basicamente a definição de um cenário de decisão é feita em um step "formula". É lá onde colocamos a formula de identificação do cenário. Dessa forma, quando o cenário é identificado, este é atribuído a aquela classe. Os passso posteriores consistem em selecionar apenas as classes que ocorreram os cenários, buscar as chaves de seus atributos nas dimensões para então carregar uma tupla na tabela de fatos. Mais detalhes sobre o processo de ETL pode ser vista no apendice TAL.


Os processos de ETL para carregar os fatos relacionado aos valores das métricas foram mais simples, pois foi basicamente armazenar o relatório fornecido pelas ferramentas. A única diferença é que foram selecionados apenas as métricas de interesse, que estão sendo utilizadas pelos cenários implementados.

\subsection{Ferramentas de Acesso aos dados - DAT}

A DAT é composta pelas ferramentas que dão acesso aos dados e permitem fazer consultas OLAP. As Ferramentas de Acesso a Dados são ferramentas que tem a capacidade de realizar consulta aos dados da Área de Apresentação. Elas podem variar desde simples ferramentas de consulta \emph{ad-hoc} até ferramentas de análises complexas e de mineração de dados \cite{kimball2002}.


Para visualizar os dados e realizar consultas OLAP e gerar relatórios, foi utilizado a ferramenta Pentaho Business Inteligence Server (conhecida como BI sever). Essa ferramenta ainda inclui a tecnologia de cliente e servidor, possibilitando o acesso de diversos usuários a um sistema de consultas e análise em rede. Ela conta com diversos plugins que realizam diversas operações, tais como, geração de gráficos, visualização de dados em tabelas, etc. O Plugin utilizado para a visualizãção dos dados e geração de consultas OLAP foi o Saiku Analytics.

Porém, para visualizar os dados, é necessário primeiramente criar cubos de dados. Criar um Cubo de dados consiste em definir quais serão os fatos e dimensões envolvidos, como também definir as hierarquias e agregações que serão feitas em cima dos dados no momento das análise. A modelagem dimensional busca representar os dados no formato de cubos. Tomando como exemplo um cubo mágico, um cubo de dados teria os lados como as dimensões e cada célula do cubo seria um fato que estaria relacionado com um valor de cada uma dessas dimensões associadas.


Para criação e publicação do cubos de dados, foi utilizado a ferramenta mondrian. Esta gera um arquivo XML com todas as configurações definidas do cubo, que é usado pelo BI server para gerar os relatórios e fazer as conultas OLAP à base de dados.


\subsection{Resumo do Ambiente de DWing Criado}

Na figura TAL, é apresentado como cada ferramenta ficou disposta a arquitetura de componentes de um ambiente de DWing apresentada no inicio dessa sessão.



\section{Projetos analisados}
\label{cap-projects}

Nesta monografia definimos a técnica de Cenários de Decisão e propomos um conjunto de cenários para tomada de decisão sobre a segurança do software, seja a partir da utilização de métricas de \emph{design} ou através de métricas de vulnerabilidades. Para apresentar como estes cenários podem ser utilizados, foram analisados três softwares livres. 

Como discutido no Seção \ref{cap-cenarios-sec-definicaocenarios} do Capítulo de Cenários, nos restringimos a apenas projetos escritos em C++. A seguir é feita uma pequena introdução à cada um dos projetos escolhidos.

\subsection{GNU Octave}
\label{section-octave}

O GNU Octave é um projeto desenvolvido em C++ que consiste em uma linguagem interpretada de alto nível destinada à computação matemática distribuída através da licença GNU General Public License \footnote{\url{http://www.gnu.org/copyleft/gpl.html}}. Ele possui uma interface baseada em linha de comando para a solução de problemas matemáticas lineares e não lineares, assim como possibilita a execução de experimentos numéricos. Além disso, também provê um conjunto extensivo de ferramentas para geração de gráficos, visualização e manipulação de dados.

Outras informações específicas sobre o projeto GNU Octave podem ser obtidas através da documentação oficial do projeto, disponível na página \url{https://www.gnu.org/software/octave/}.

O código fonte do projeto está disponível na página \url{ftp://ftp.gnu.org/gnu/octave}. Lá, além da versão atual, podemos ter acesso ao código de releases anteriores.

Este projeto será analisado tanto através do Mezuro quanto através do DWing.


==== MOSTRAR OS CENÀRIOS EM CADA FERRAMENTA ====


\subsection{Athom Shell}
\label{section-athom}

O Athom Shell é um framework desenvolvido em C++ que permite escrever aplicações \emph{desktop} multi-plataforma através de JavaScript, HTML e CSS. Esse framework é baseado em node.js\footnote{\url{http://nodejs.org/}} e no Chromium e é usada no editor de texto Athom\footnote{\url{https://atom.io/}}. Esse projeto é distribuído através da licença MIT\footnote{\url{http://opensource.org/licenses/MIT}}.

A documentação oficial do projeto pode ser encontrada no próprio repositório principal\footnote{\url{https://github.com/atom/atom-shell}} através da url: \url{https://github.com/atom/atom-shell/tree/master/docs}.

Avaliação através do mezuro pode ser vista em: \url{http://mezuro.org/projects/33/repositories/58}

\subsection{Projeto 3}
\label{}

Projeto a ser analisado somente através do DWing


\section{Coleta de Dados}
\label{data-colect}

O Mezuro já trabalha em conjunto com o Analizo\footnote{\url{http://www.analizo.org/}}. O Analizo é uma ferramenta de análise estática de código e dá suporte a diversas métricas, inclusive as métricas discutidas no cápitulo 2, tanto de \emph{design} quanto de vulnerabilidade. Um ambiente de DW não está atrelado a apenas uma fonte de dados, podendo utilizar diversas fontes. Dessa forma, utilizamos o Analizo para coletar as métricas e gerar o insumo para a análise dos cenários em ambas as ferramentas.

Porém, identificamos um problema com o Analizo em relação as coleta de métricas de vulnerabilidade. Para projetos pequenos e simples as métricas de vulnerabilidade podem ser coletadas.  Contudo, para projetos maiores e mais complexos, com arquitetura bem definida, o Analizo não consegue gerar tais métricas. Isso se deve ao fato do Analizo utilizar o \emph{Clang Static Analizer}\footnote{\url{http://clang-analyzer.llvm.org/}}, que é outra ferramenta livre que faz análise estática para identificação de bugs em projetos C/C++, para a geração das métricas de vulnerabilidade. A utilização do \emph{clang} consiste em chamar o comando \emph{scan-build}  e o comando de compilação do programa, por exemplo \emph{\"scan-build gcc myprog.c\"}. Foi verificado que o Analizo chama o \emph{clang} em seu código para cada arquivo, usando apenas o comando \emph{gcc} em cada um deles. Isso pode funcionar para projetos simples, porém projetos mais complexos são compilados geralmente com \emph{\"Makefile\"}, com diversas linhas de compilação. Não consguindo compilar o código, o \emph{clang} não consegue executar, fazendo com que o Analizo, por sua vez, não consiga extrair as métricas de vulnerabilidade. 

Grandes alterações deveriam ser feitas para fazer com que o Analizo pudesse gerar os valores dessas métricas para projetos grantes, não cabendo ao escopo e tempo desta monografia. Esse problema afeta diretamente ao Mezuro, pois, dependente do relatório gerado pelo Analizo, não consegue os valores de métricas de vulnerabilidade para projetos maiores. Como o ambiente de DWing pode ter diversas fontes de dados, podemos recorrer a outra fonte de dados que ofereça apenas as métricas de segurança.

Dessa forma, decidimos em usar o \emph{clang} para extrair as métricas de vulnerabilidade. O \emph{clang} gera um relatório no formato HTML. Foi feito um parser para transformar o HTML em um arquivo CSV, com a mesma estrutura fornecida pelo Analizo. Assim, o ambiente de DWing pode utilizar desse arquivo CSV gerado pelo parser para se alimentar das métricas de vulnerabildade da mesma maneira que trata o CSV gerado pelo próŕio Analizo. O parser foi desenvolvido na linguagem perl justamente para aproveitarmos das lógicas de programação e códigos do próprio Analizo.

======== EXPLICAR COMO O MEZURO UTILIZA OS DADOS do Analizo, Como funciona a Integração(brevemente)=====


======== EXPLICAR BREVEMENTE ETL DW =====



\section{Análise dos Cenários nas Ferramentas}

Nesta seção será apresentada Aqui, mostrar os cenários nos projetos, como podem ser visualizados, etc


\section{Conclusões}

Descrever as conclusoes obtidas com a execução do estudo de caso